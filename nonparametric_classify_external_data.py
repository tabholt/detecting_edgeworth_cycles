'''
Author: Timothy Holt - tabholt@gmail.com
Sep 2023

External Classification using Pre-trained Models.

This script performs external classification using pre-trained machine
learning models. It loads external data in either JSON or CSV format,
processes it, and uses a pre-trained model to classify the data. The
classification results are then exported to a JSON or CSV file.

Parameters:
    pretrained_model_tsh (str): The hash of the pre-trained model to be
        used.
    external_data_path (str): The path to the external data file in JSON or
        CSV format.
    model_type (str): The type of pre-trained model ('rf', 'lstm_basic',
        'lstm_ensemble').
    region (str): The region of the pre-trained model ('de', 'nsw', 'wa').
    results_export_filename (str): The name of the file to export
        classification results.

Advanced Parameters (usually not updated):
    pretrained_models_root (str): Root directory for pre-trained models.
    series_prefix (str): Prefix for numbered data columns in CSV input.
    id_column_name (str): Column name for unique identifiers in CSV input.
    series_name (str): Name of the data field in JSON input.

Functions:
    - load_non_param_model(model_type, region, tsh): Loads a pre-trained
      model based on the type and region.
    - convert_json_price_matrix(external_data_path, series_name): Converts
      JSON data into a price matrix.
    - convert_csv_price_matrix(external_data_path, series_prefix,
      id_column_name): Converts CSV data into a price matrix.
    - build_X_lstm(lstm_model, sims): Builds input data for LSTM models.
    - build_X_rf(rf_model, sims): Builds input data for Random Forest
      models.
    - export_results(dictionary, filename): Exports classification results
      to JSON or CSV.

Usage:
    - requires saved LSTM or RF model (see run_lstm_model.py or run_rf_model.py)
    - add training set hash to pretrained_model_tsh in the SET PARAMETERS 
      section
    - training set hash is the 32-character random-looking text string
      that is can be extracted from the logs 
    - add path to external data in the SET PARAMETERS section
        - data must be in either json or csv format
        - format must be consistent with files generated by 
          convert_price_window_json_csv.py script. 
    - set model_type in SET PARAMETERS section
    - call this script using python
    - classification results will be saved to file: results_export_filename

Note:
    - This script assumes that pre-trained models exist for the specified
      region and model type.
    - The external data must be properly formatted according to the chosen
      input format (JSON or CSV).
    - The classification results are saved in either JSON or CSV format
      based on the specified filename.
'''

import os
import sys
import pickle
import json
import numpy as np
import pandas as pd
np.set_printoptions(edgeitems=8, precision=4, suppress=True, linewidth=180)

#################### SET PARAMETERS ####################
# basic settings (should be updated)
pretrained_model_tsh = '32a0cdf61a24144c4b83df822a4302da' # add hash from a pre-trained model
external_data_path = 'label_databases/ALL_detrended_price_windows.json' # either json or csv
model_type = 'lstm_basic' # in {'rf', 'lstm_basic', 'lstm_ensemble'}
region = 'de' # in {'de', 'nsw', 'wa'} the region of the pre-trained model
results_export_filename = f'{model_type}_external_classification_results.json' # either json or csv

# advanced settings (recommend to not update)
pretrained_models_root = 'pretrained_models/'
series_prefix = 'det_p' # for csv input: prefix to numbered data columns
id_column_name = 'uuid' # for csv input: column name for unique identifiers
series_name = 'detrended_price' # for json input: name of data field
########################################################


def load_non_param_model(model_type, region, tsh):
    if model_type == 'rf':
        print(f'loading RF model {tsh}...')
        path = pretrained_models_root + f'rf_models/{region}/{tsh}/'
        pkl_file = path + 'RF_Model.pkl'
    elif model_type == 'lstm_basic':
        print(f'loading basic LSTM model {tsh}...')
        path = pretrained_models_root + f'lstm_models/basic/{region}/{tsh}/'
        pkl_file = path + 'LSTM_Model.pkl'
    elif model_type == 'lstm_ensemble':
        print(f'loading ensemble LSTM model {tsh}...')
        path = pretrained_models_root + f'lstm_models/ensemble/{region}/{tsh}/'
        pkl_file = path + 'LSTM_Model.pkl'
    if not os.path.exists(pkl_file):
        if 'lstm' in model_type:
            model_type = 'lstm'
        missing_model = f'Pre-trained model {pkl_file} does not exist. See run_{model_type}_model.py to train and save a model.'
        raise Exception(missing_model)
    with open(pkl_file, 'rb') as pickle_file:
        model = pickle.load(pickle_file)
    if model_type in ['lstm_ensemble', 'lstm_basic']:
        try:
            os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}
            old_stdout = sys.stdout
            sys.stdout = open(os.devnull, 'w')
            model.saved_network_dir = pretrained_models_root + 'lstm_models/'
            model.load_pretrained_network()
            sys.stdout = old_stdout
        except:
            raise Exception(
                'Unable to load saved TensorFlow networks. Check version of TF.')
    if model_type == 'rf':
        model.extract_features()
    return model


def convert_json_price_matrix(external_data_path, series_name='detrended_price'):
    with open(external_data_path, 'rb') as json_file:
        db = json.load(json_file)
    price_matrix = np.ndarray((len(db), 90))
    for i, ob in enumerate(db.values()):
        price_matrix[i, :] = ob[series_name]
    col_labels = list(db.keys())
    return col_labels, price_matrix

def convert_csv_price_matrix(external_data_path, series_prefix='det_p', id_column_name='uuid'):
    df = pd.read_csv(external_data_path)
    series_column_labels = [f'{series_prefix}{i}' for i in range(90)]
    price_matrix = df[series_column_labels].to_numpy()
    col_labels = df[id_column_name].tolist()
    if id_column_name == 'uuid' and 'start_date' in df.columns:
        dates = df['start_date'].to_list()
        col_labels = [f'{uuid}_{dates[i]}_90' for i, uuid in enumerate(col_labels)]
    return col_labels, price_matrix


def build_X_lstm(lstm_model, sims):
    n = sims.shape[0]
    m = lstm_model.data.train
    m.method_arrays = {}
    if len(lstm_model.feature_list) > 0:
        for i, method in enumerate(lstm_model.feature_list):
            if method == 'MBPI':
                continue
            else:
                m.evaluate_external_data(sims, method)
        features = m.method_arrays
        features['LS'] = m.LS_array_external_data(sims)
        if 'MBPI' in lstm_model.feature_list:
            MBPI_theta1_star = m.MBPI_theta1_star
            m.evaluate_external_data(sims, 'MBPI')
            features['MBPI'] = m.g_MBPI(MBPI_theta1_star)
    else:
        features = {}
    features['delta_p'] = sims[:, 1:] - sims[:, :-1]
    X = np.ndarray((n, 90, len(features)))
    for i, feat in enumerate(features):
        f = features[feat]
        if len(f.shape) == 1:
            x = np.ndarray((n, 90))
            x.fill(0)
            x[:, 0] = f
        elif f.shape[1] < 90:
            a = np.ndarray((n, 90-f.shape[1]))
            a.fill(0)
            x = np.concatenate((f, a), axis=1)
        else:
            x = f
        X[:, :, i] = x
    return X

def build_X_rf(rf_model, sims):
    n = sims.shape[0]
    m = rf_model.data.train
    features = rf_model.feature_list
    X = np.ndarray((n, len(features)))
    for i, method in enumerate(features):
        if method == 'MBPI':
            MBPI_theta1_star = m.MBPI_theta1_star
            m.evaluate_external_data(sims, method)
            X[:, i] = m.g_MBPI(MBPI_theta1_star)
        else:
            m.evaluate_external_data(sims, method)
            X[:, i] = m.method_arrays[method]
    return X


def export_results(dictionary, filename):
    print(f'Saving classification results to: {filename}')
    if filename.split('.')[-1] == 'json':
        with open(filename, 'w') as json_f:
            export_json = json.dumps(dictionary, indent=4)
            json_f.write(export_json)
    elif filename.split('.')[-1] == 'csv':
        df = pd.DataFrame.from_dict(dictionary, orient='index', columns=['classification'])
        df.to_csv(filename, index_label=id_column_name)
    else:
        raise Exception('Incompatible export file type. Must be json or csv.')


def main():
    print(f'loading data from: {external_data_path}...')
    if external_data_path.split('.')[-1] == 'json':
        col_labels, price_matrix = convert_json_price_matrix(
            external_data_path,
            series_name=series_name,
            )
    elif external_data_path.split('.')[-1] == 'csv':
        col_labels, price_matrix = convert_csv_price_matrix(
            external_data_path,
            series_prefix=series_prefix,
            id_column_name=id_column_name
            )
    else:
        raise Exception('Incompatible file type. Must be json or csv.')
    model = load_non_param_model(model_type, region, pretrained_model_tsh)
    if model_type == 'rf':
        X = build_X_rf(model, price_matrix)
    elif model_type in {'lstm_ensemble', 'lstm_basic'}:
        X = build_X_lstm(model, price_matrix)
    evals = model.network.predict(X)
    evals = np.where(evals < 0.5, 0, 1)
    evals = evals.flatten().tolist()
    lstm_classifications = dict(zip(col_labels, evals))
    export_results(lstm_classifications, results_export_filename)

if __name__ == '__main__':
    main()