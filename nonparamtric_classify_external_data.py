'''
Author: Timothy Holt - tabholt@gmail.com
Sep 2023

Load Saved LSTM or RF model and use the network to classify external data.
To Use:
    - requires saved LSTM or RF model (see run_lstm_model.py or run_rf_model.py)
    - add training set hash to pretrained_model_tsh in the SET PARAMETERS 
      section
        - training set hash is the 32-character random-looking text string
          that is can be extracted from the logs 
    - add path to external data in the SET PARAMETERS section
        - data must be in either json or csv format
        - format must be consistent with files generated by 
          convert_price_window_json_csv.py script. 
    - set model_type in SET PARAMETERS section
    - call this script using python
    - classification results will be saved to file: results_export_filename
'''

import os
import sys
import pickle
import json
import numpy as np
import pandas as pd
np.set_printoptions(edgeitems=8, precision=4, suppress=True, linewidth=180)

#################### SET PARAMETERS ####################
# basic settings (should be updated)
pretrained_model_tsh = '5e902479bedaf4d15cd967c7d4b8db61' # add hash from a pre-trained model
external_data_path = 'label_databases/ALL_detrended_price_windows.json'
model_type = 'lstm_ensemble' # in {'rf', 'lstm_basic', 'lstm_ensemble'}
region = 'de' # in {'de', 'nsw', 'wa'} the region of the pre-trained model
results_export_filename = f'{model_type}_external_classification_results.json' # either json or csv

# advanced settings (recommend to not update)
pretrained_models_root = 'pretrained_models/'
series_prefix = 'det_p' # for csv input: prefix to numbered data columns
id_column_name = 'uuid' # for csv input: column name for unique identifiers
series_name = 'detrended_price' # for json input: name of data field
########################################################


def load_non_param_model(model_type, region, tsh):
    if model_type == 'rf':
        print(f'loading RF model {tsh}...')
        path = pretrained_models_root + f'rf_models/{region}/{tsh}/'
        pkl_file = path + 'RF_Model.pkl'
    elif model_type == 'lstm_basic':
        print(f'loading basic LSTM model {tsh}...')
        path = pretrained_models_root + f'lstm_models/basic/{region}/{tsh}/'
        pkl_file = path + 'LSTM_Model.pkl'
    elif model_type == 'lstm_ensemble':
        print(f'loading ensemble LSTM model {tsh}...')
        path = pretrained_models_root + f'lstm_models/ensemble/{region}/{tsh}/'
        pkl_file = path + 'LSTM_Model.pkl'
    if not os.path.exists(pkl_file):
        raise Exception(f'Pre-trained model {pkl_file} does not exist. See run_lstm_model.py to train and save a model.')
    with open(pkl_file, 'rb') as pickle_file:
        model = pickle.load(pickle_file)
    if model_type in ['lstm_ensemble', 'lstm_basic']:
        try:
            os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}
            old_stdout = sys.stdout
            sys.stdout = open(os.devnull, 'w')
            model.saved_network_dir = pretrained_models_root + 'lstm_models/'
            model.load_pretrained_network()
            sys.stdout = old_stdout
        except:
            raise Exception(
                'Unable to load saved TensorFlow networks. Check version of TF.')
    if model_type == 'rf':
        model.extract_features()
    return model


def convert_json_price_matrix(external_data_path, series_name='detrended_price'):
    with open(external_data_path, 'rb') as json_file:
        db = json.load(json_file)
    price_matrix = np.ndarray((len(db), 90))
    for i, ob in enumerate(db.values()):
        price_matrix[i, :] = ob[series_name]
    col_labels = list(db.keys())
    return col_labels, price_matrix

def convert_csv_price_matrix(external_data_path, series_prefix='det_p', id_column_name='uuid'):
    df = pd.read_csv(external_data_path)
    series_column_labels = [f'{series_prefix}{i}' for i in range(90)]
    price_matrix = df[series_column_labels].to_numpy()
    col_labels = df[id_column_name].tolist()
    if id_column_name == 'uuid' and 'start_date' in df.columns:
        dates = df['start_date'].to_list()
        col_labels = [f'{uuid}_{dates[i]}_90' for i, uuid in enumerate(col_labels)]
    return col_labels, price_matrix


def build_X_lstm(lstm_model, sims):
    n = sims.shape[0]
    m = lstm_model.data.train
    m.method_arrays = {}
    if len(lstm_model.feature_list) > 0:
        for i, method in enumerate(lstm_model.feature_list):
            if method == 'MBPI':
                continue
            else:
                m.evaluate_external_data(sims, method)
        features = m.method_arrays
        features['LS'] = m.LS_array_external_data(sims)
        if 'MBPI' in lstm_model.feature_list:
            MBPI_theta1_star = m.MBPI_theta1_star
            m.evaluate_external_data(sims, 'MBPI')
            features['MBPI'] = m.g_MBPI(MBPI_theta1_star)
    else:
        features = {}
    features['delta_p'] = sims[:, 1:] - sims[:, :-1]
    X = np.ndarray((n, 90, len(features)))
    for i, feat in enumerate(features):
        f = features[feat]
        if len(f.shape) == 1:
            x = np.ndarray((n, 90))
            x.fill(0)
            x[:, 0] = f
        elif f.shape[1] < 90:
            a = np.ndarray((n, 90-f.shape[1]))
            a.fill(0)
            x = np.concatenate((f, a), axis=1)
        else:
            x = f
        X[:, :, i] = x
    return X

def build_X_rf(rf_model, sims):
    n = sims.shape[0]
    m = rf_model.data.train
    features = rf_model.feature_list
    X = np.ndarray((n, len(features)))
    for i, method in enumerate(features):
        if method == 'MBPI':
            MBPI_theta1_star = m.MBPI_theta1_star
            m.evaluate_external_data(sims, method)
            X[:, i] = m.g_MBPI(MBPI_theta1_star)
        else:
            m.evaluate_external_data(sims, method)
            X[:, i] = m.method_arrays[method]
    return X


def export_results(dictionary, filename):
    print(f'Saving classification results to: {filename}')
    if filename.split('.')[-1] == 'json':
        with open(filename, 'w') as json_f:
            export_json = json.dumps(dictionary, indent=4)
            json_f.write(export_json)
    elif filename.split('.')[-1] == 'csv':
        df = pd.DataFrame.from_dict(dictionary, orient='index', columns=['classification'])
        df.to_csv(filename, index_label=id_column_name)
    else:
        raise Exception('Incompatible export file type. Must be json or csv.')


def main():
    print(f'loading data from: {external_data_path}...')
    if external_data_path.split('.')[-1] == 'json':
        col_labels, price_matrix = convert_json_price_matrix(
            external_data_path,
            series_name=series_name,
            )
    elif external_data_path.split('.')[-1] == 'csv':
        col_labels, price_matrix = convert_csv_price_matrix(
            external_data_path,
            series_prefix=series_prefix,
            id_column_name=id_column_name
            )
    else:
        raise Exception('Incompatible file type. Must be json or csv.')
    model = load_non_param_model(model_type, 'de', pretrained_model_tsh)
    if model_type == 'rf':
        X = build_X_rf(model, price_matrix)
    elif model_type in {'lstm_ensemble', 'lstm_basic'}:
        X = build_X_lstm(model, price_matrix)
    evals = model.network.predict(X)
    evals = np.where(evals < 0.5, 0, 1)
    evals = evals.flatten().tolist()
    lstm_classifications = dict(zip(col_labels, evals))
    export_results(lstm_classifications, results_export_filename)

if __name__ == '__main__':
    main()